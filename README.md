# Проєкт: Прогнозування підписки на депозит клієнтами банку

## Мета проєкту

Метою проєкту є побудова моделі машинного навчання, яка передбачає, чи підпише клієнт строковий депозит на основі демографічних та соціально-економічних даних. Використано датасет **Bank Marketing** з UCI Machine Learning Repository. Цільова змінна: `y` (yes/no).

## Що було зроблено

- Проведено попередню обробку даних:
  - Визначено числові та категоріальні змінні
  - Проведено масштабування числових ознак (MinMaxScaler)
  - Проведено one-hot кодування категоріальних ознак (OneHotEncoder)
- Розділено дані на навчальну та валідаційну вибірки
- Побудовано кілька моделей:
  - Logistic Regression
  - K-Nearest Neighbors
  - Decision Tree
  - XGBoost (з підбором гіперпараметрів через Hyperopt та RandomizedSearchCV)
- Здійснено оцінку моделей за метриками:
  - ROC AUC
  - F1-score
  - Precision
  - Recall
- Візуалізовано матриці та ROC-криві
- Проведено аналіз помилок моделі
- Здійснено інтерпретацію ознак з SHAP

## Порівняння моделей

| Модель                          | Гіперпараметри                                                                                                                | Train метрики                       | Val метрики                         | Коментар |
|--------------------------------|--------------------------------------------------------------------------------------------------------------------------------|-------------------------------------|-------------------------------------|----------|
| Logistic Regression            | `class_weight=balanced, solver='liblinear'`                                                                                    | AUC=0.79, F1=0.44, P=0.34, R=0.63   | AUC=0.79, F1=0.45, P=0.35, R=0.65   | Базова модель, хороша рекол, але слабка точність |
| KNeighborsClassifier           | `n_neighbors=24, weights='uniform'`                                                                                            | AUC=0.84, F1=0.26, P=0.75, R=0.16   | AUC=0.76, F1=0.22, P=0.66, R=0.13   | Дуже слабкий recall — не підходить для задачі |
| DecisionTreeClassifier         | `max_leaf_nodes=9, max_depth=5`                                                                                                | AUC=0.77, F1=0.30, P=0.71, R=0.19   | AUC=0.79, F1=0.28, P=0.70, R=0.18   | Схожа на KNN, краще інтерпретується |
| XGBClassifier (Hyperopt)       | `n_estimators=60, max_depth=10, learning_rate=0.063..., subsample=0.85, colsample_bytree=0.91, reg_alpha=0.76, reg_lambda=0.57` | AUC=0.89, F1=0.53, P=0.87, R=0.38   | AUC=0.81, F1=0.37, P=0.64, R=0.26   | Добре підганяється під тренувальні дані, але переобучення |
| XGBClassifier (RandSearchCV)   | `colsample_bytree=0.68, gamma=3.36, learning_rate=0.0077, max_depth=9, ..., n_estimators=1084`                                 | AUC=0.84, F1=0.42, P=0.75, R=0.30   | AUC=0.82, F1=0.35, P=0.63, R=0.25   | Краще збалансована модель, більш стабільна |

## Висновки

- Найкращі результати на валідації показала **Logistic Regression**, незважаючи на простоту.
- **XGBoost з Hyperopt** має найвищу F1 на train, але є перенавчання.
- Моделі KNN та Decision Tree мають низький recall, не підходять для задачі з класовим дисбалансом.
- Проведений аналіз SHAP підтвердив важливість ознак `duration`, `poutcome`, `nr.employed`, `month`, `euribor3m` — це логічно, оскільки вони відображають результат попередніх кампаній та економічну ситуацію.
- Аналіз помилок вказав, що моделі часто плутають класи, коли `duration` короткий, або `poutcome` був негативний.

## Що ще можна зробити

- Збалансувати дані за допомогою **SMOTE** або **undersampling**
- Ввести **feature selection** або **боротьбу з кореляцією ознак**
- Спробувати **stacking** або **ensemble** моделей
- Погратись з **threshold tuning** замість фіксованого порогу 0.5
- Провести більш глибокий **EDA**, зокрема взаємозв’язки ознак

